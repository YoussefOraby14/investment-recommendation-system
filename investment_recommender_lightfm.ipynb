{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T13:53:28.741154Z",
     "iopub.status.busy": "2026-01-19T13:53:28.740886Z",
     "iopub.status.idle": "2026-01-19T13:53:46.607989Z",
     "shell.execute_reply": "2026-01-19T13:53:46.607294Z",
     "shell.execute_reply.started": "2026-01-19T13:53:28.741133Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightfm\n",
      "  Downloading lightfm-1.17.tar.gz (316 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.4/316.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from lightfm) (1.26.4)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.11/dist-packages (from lightfm) (1.15.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from lightfm) (2.32.3)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from lightfm) (1.2.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->lightfm) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->lightfm) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->lightfm) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->lightfm) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->lightfm) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->lightfm) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->lightfm) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->lightfm) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->lightfm) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->lightfm) (2025.1.31)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->lightfm) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->lightfm) (3.6.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->lightfm) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->lightfm) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->lightfm) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->lightfm) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->lightfm) (2024.2.0)\n",
      "Building wheels for collected packages: lightfm\n",
      "  Building wheel for lightfm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for lightfm: filename=lightfm-1.17-cp311-cp311-linux_x86_64.whl size=829306 sha256=f6c949cfb3b7618aeb033986919cded51764867da594dc87ba248b13746c0d55\n",
      "  Stored in directory: /root/.cache/pip/wheels/b9/0d/8a/0729d2e6e3ca2a898ba55201f905da7db3f838a33df5b3fcdd\n",
      "Successfully built lightfm\n",
      "Installing collected packages: lightfm\n",
      "Successfully installed lightfm-1.17\n",
      "Precision@10: 0.0650\n",
      "ROI Threshold: 0.2200\n",
      "ROI@10: 1.0015\n",
      "nDCG@10: 0.5070\n"
     ]
    }
   ],
   "source": [
    "!pip install lightfm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# === 1. Load Data ===\n",
    "transactions = pd.read_csv(\"/kaggle/input/dataset3/transactions.csv\")\n",
    "limit_prices = pd.read_csv(\"/kaggle/input/dataset3/limit_prices.csv\")\n",
    "customers = pd.read_csv(\"/kaggle/input/dataset3/customer_information.csv\")\n",
    "assets = pd.read_csv(\"/kaggle/input/dataset3/asset_information.csv\")\n",
    "\n",
    "# === 2. Filter buy transactions ===\n",
    "buy_data = transactions[transactions[\"transactionType\"] == \"Buy\"].drop_duplicates(subset=[\"customerID\", \"ISIN\"])\n",
    "\n",
    "# === 3. Merge data ===\n",
    "customers_latest = customers.sort_values(\"timestamp\").drop_duplicates(subset=\"customerID\", keep=\"last\")\n",
    "merged = buy_data.merge(customers_latest, on=\"customerID\").merge(\n",
    "    assets[[\"ISIN\", \"assetCategory\", \"sector\", \"industry\"]], on=\"ISIN\"\n",
    ")\n",
    "filtered = merged.copy()\n",
    "\n",
    "# === 4. Filter rarely traded assets ===\n",
    "popular_assets = buy_data[\"ISIN\"].value_counts()[lambda x: x > 5].index\n",
    "filtered = filtered[filtered[\"ISIN\"].isin(popular_assets)]\n",
    "\n",
    "# === 5. Split ===\n",
    "train_data, test_data = train_test_split(filtered, test_size=0.1, random_state=42)\n",
    "\n",
    "# === 6. Encode IDs and features ===\n",
    "dataset = Dataset()\n",
    "user_feature_fields = [\"riskLevel\", \"customerType\", \"investmentCapacity\"]\n",
    "users_list = customers_latest[user_feature_fields].fillna(\"Unknown\").astype(str)\n",
    "user_feature_tuples = [\n",
    "    (row[\"customerID\"], [\n",
    "        f\"riskLevel:{row['riskLevel']}\",\n",
    "        f\"type:{row['customerType']}\",\n",
    "        f\"capacity:{row['investmentCapacity']}\"\n",
    "    ]) for _, row in users_list.join(customers_latest[\"customerID\"]).iterrows()\n",
    "]\n",
    "valid_customers = set(filtered[\"customerID\"])\n",
    "filtered_user_feature_tuples = [(uid, feats) for uid, feats in user_feature_tuples if uid in valid_customers]\n",
    "\n",
    "dataset.fit(\n",
    "    users=filtered[\"customerID\"],\n",
    "    items=filtered[\"ISIN\"],\n",
    "    user_features={f for _, feats in filtered_user_feature_tuples for f in feats}\n",
    ")\n",
    "\n",
    "train_interactions, _ = dataset.build_interactions(list(zip(train_data[\"customerID\"], train_data[\"ISIN\"])))\n",
    "test_interactions, _ = dataset.build_interactions(list(zip(test_data[\"customerID\"], test_data[\"ISIN\"])))\n",
    "user_features = dataset.build_user_features(filtered_user_feature_tuples)\n",
    "\n",
    "# === 7. Train Model ===\n",
    "model = LightFM(loss=\"warp-kos\")\n",
    "model.fit(train_interactions, user_features=user_features, epochs=10, num_threads=4)\n",
    "\n",
    "# === 8. Evaluate Precision@10 ===\n",
    "precision = precision_at_k(model, test_interactions, user_features=user_features, k=10).mean()\n",
    "print(f\"Precision@10: {precision:.4f}\")\n",
    "\n",
    "# === 9. Inverse Mapping ===\n",
    "user_id_map, _, item_id_map, _ = dataset.mapping()\n",
    "inv_user_id_map = {v: k for k, v in user_id_map.items()}\n",
    "inv_item_id_map = {v: k for k, v in item_id_map.items()}\n",
    "\n",
    "# === 10. Threshold ===\n",
    "def auto_select_threshold(profitability_series):\n",
    "    stats = profitability_series.describe()\n",
    "    median, q3, minv, maxv = stats[\"50%\"], stats[\"75%\"], stats[\"min\"], stats[\"max\"]\n",
    "    if maxv - minv > 10 * abs(median): return q3\n",
    "    elif median > 0: return median\n",
    "    return 0.01\n",
    "\n",
    "roi_threshold = auto_select_threshold(limit_prices[\"profitability\"])\n",
    "print(f\"ROI Threshold: {roi_threshold:.4f}\")\n",
    "\n",
    "# === 11. Recommend + Metrics ===\n",
    "def recommend_with_metrics(model, interactions, top_k=10, sample_users=10):\n",
    "    n_users, n_items = interactions.shape\n",
    "    all_recommendations, roi_at_k_list, ndcg_list = [], [], []\n",
    "\n",
    "    for uid in range(min(sample_users, n_users)):\n",
    "        actual_user_id = inv_user_id_map[uid]\n",
    "        scores = model.predict(uid, np.arange(n_items), user_features=user_features)\n",
    "        sorted_items = np.argsort(-scores)\n",
    "\n",
    "        top_assets = []\n",
    "        for iid in sorted_items:\n",
    "            isin = inv_item_id_map[iid]\n",
    "            if isin not in limit_prices[\"ISIN\"].values: continue\n",
    "            roi = limit_prices.loc[limit_prices[\"ISIN\"] == isin, \"profitability\"].values[0]\n",
    "            if roi <= roi_threshold: continue\n",
    "\n",
    "            asset_row = assets[assets[\"ISIN\"] == isin].iloc[0]\n",
    "            top_assets.append((isin, roi))\n",
    "            if len(top_assets) >= top_k: break\n",
    "\n",
    "        roi_values = [r[1] for r in top_assets]\n",
    "        if roi_values:\n",
    "            roi_at_k = np.mean(roi_values)\n",
    "            roi_at_k_list.append(roi_at_k)\n",
    "\n",
    "            ideal = sorted(roi_values, reverse=True)\n",
    "            dcg = sum([(2**r - 1) / np.log2(idx + 2) for idx, r in enumerate(roi_values)])\n",
    "            idcg = sum([(2**r - 1) / np.log2(idx + 2) for idx, r in enumerate(ideal)])\n",
    "            ndcg = dcg / idcg if idcg != 0 else 0\n",
    "            ndcg_list.append(ndcg)\n",
    "\n",
    "    print(f\"ROI@10: {np.mean(roi_at_k_list):.4f}\")\n",
    "    print(f\"nDCG@10: {np.mean(ndcg_list):.4f}\")\n",
    "\n",
    "recommend_with_metrics(model, test_interactions)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 535863,
     "sourceId": 984605,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7295738,
     "sourceId": 11628599,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7296806,
     "sourceId": 11630101,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7296885,
     "sourceId": 11630211,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7296919,
     "sourceId": 11630267,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7698556,
     "sourceId": 12219692,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
